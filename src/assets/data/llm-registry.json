{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$comment": "LLM Registry - Central model database for llm-cost-engine. All pricing in USD per 1M tokens.",
  "metadata": {
    "version": "1.0.0",
    "last_updated": "2026-01-31",
    "base_currency": "USD",
    "pricing_unit": "per_1M_tokens",
    "maintained_by": "llm-cost-engine",
    "update_frequency": "weekly"
  },
  "providers": {
    "openai": {
      "name": "OpenAI",
      "website": "https://openai.com",
      "api_docs": "https://platform.openai.com/docs"
    },
    "anthropic": {
      "name": "Anthropic",
      "website": "https://anthropic.com",
      "api_docs": "https://docs.anthropic.com"
    },
    "google": {
      "name": "Google",
      "website": "https://cloud.google.com/vertex-ai",
      "api_docs": "https://cloud.google.com/vertex-ai/docs"
    },
    "mistral": {
      "name": "Mistral AI",
      "website": "https://mistral.ai",
      "api_docs": "https://docs.mistral.ai"
    },
    "meta": {
      "name": "Meta",
      "website": "https://llama.meta.com",
      "api_docs": "https://llama.meta.com/docs"
    },
    "cohere": {
      "name": "Cohere",
      "website": "https://cohere.com",
      "api_docs": "https://docs.cohere.com"
    },
    "deepseek": {
      "name": "DeepSeek",
      "website": "https://deepseek.com",
      "api_docs": "https://platform.deepseek.com/docs"
    }
  },
  "models": [
    {
      "id": "gpt-4o",
      "name": "GPT-4o",
      "provider": "OpenAI",
      "provider_id": "openai",
      "description": "Most advanced multimodal model with vision, audio, and text capabilities",
      "release_date": "2024-05-13",
      "pricing": {
        "input_1m": 2.50,
        "output_1m": 10.00,
        "cached_input_1m": 1.25
      },
      "capabilities": {
        "context_window": 128000,
        "max_output_tokens": 16384,
        "latency_index": 0.95,
        "supports_vision": true,
        "supports_function_calling": true,
        "supports_json_mode": true,
        "supports_streaming": true
      },
      "tier": "flagship",
      "status": "active"
    },
    {
      "id": "gpt-4o-mini",
      "name": "GPT-4o Mini",
      "provider": "OpenAI",
      "provider_id": "openai",
      "description": "Affordable small model for fast, lightweight tasks",
      "release_date": "2024-07-18",
      "pricing": {
        "input_1m": 0.15,
        "output_1m": 0.60,
        "cached_input_1m": 0.075
      },
      "capabilities": {
        "context_window": 128000,
        "max_output_tokens": 16384,
        "latency_index": 0.98,
        "supports_vision": true,
        "supports_function_calling": true,
        "supports_json_mode": true,
        "supports_streaming": true
      },
      "tier": "economy",
      "status": "active"
    },
    {
      "id": "gpt-4-turbo",
      "name": "GPT-4 Turbo",
      "provider": "OpenAI",
      "provider_id": "openai",
      "description": "Previous generation flagship with vision capabilities",
      "release_date": "2024-04-09",
      "pricing": {
        "input_1m": 10.00,
        "output_1m": 30.00,
        "cached_input_1m": 5.00
      },
      "capabilities": {
        "context_window": 128000,
        "max_output_tokens": 4096,
        "latency_index": 0.85,
        "supports_vision": true,
        "supports_function_calling": true,
        "supports_json_mode": true,
        "supports_streaming": true
      },
      "tier": "flagship",
      "status": "active"
    },
    {
      "id": "o1",
      "name": "o1",
      "provider": "OpenAI",
      "provider_id": "openai",
      "description": "Reasoning model for complex problem-solving with chain-of-thought",
      "release_date": "2024-12-05",
      "pricing": {
        "input_1m": 15.00,
        "output_1m": 60.00,
        "cached_input_1m": 7.50
      },
      "capabilities": {
        "context_window": 200000,
        "max_output_tokens": 100000,
        "latency_index": 0.60,
        "supports_vision": true,
        "supports_function_calling": true,
        "supports_json_mode": true,
        "supports_streaming": true
      },
      "tier": "reasoning",
      "status": "active"
    },
    {
      "id": "o1-mini",
      "name": "o1-mini",
      "provider": "OpenAI",
      "provider_id": "openai",
      "description": "Fast reasoning model optimized for coding and STEM",
      "release_date": "2024-09-12",
      "pricing": {
        "input_1m": 3.00,
        "output_1m": 12.00,
        "cached_input_1m": 1.50
      },
      "capabilities": {
        "context_window": 128000,
        "max_output_tokens": 65536,
        "latency_index": 0.75,
        "supports_vision": false,
        "supports_function_calling": false,
        "supports_json_mode": false,
        "supports_streaming": true
      },
      "tier": "reasoning",
      "status": "active"
    },
    {
      "id": "o3-mini",
      "name": "o3-mini",
      "provider": "OpenAI",
      "provider_id": "openai",
      "description": "Next-generation compact reasoning model",
      "release_date": "2025-01-31",
      "pricing": {
        "input_1m": 1.10,
        "output_1m": 4.40,
        "cached_input_1m": 0.55
      },
      "capabilities": {
        "context_window": 200000,
        "max_output_tokens": 100000,
        "latency_index": 0.80,
        "supports_vision": false,
        "supports_function_calling": true,
        "supports_json_mode": true,
        "supports_streaming": true
      },
      "tier": "reasoning",
      "status": "active"
    },
    {
      "id": "claude-3.5-sonnet",
      "name": "Claude 3.5 Sonnet",
      "provider": "Anthropic",
      "provider_id": "anthropic",
      "description": "High-performance model balancing intelligence and speed",
      "release_date": "2024-06-20",
      "pricing": {
        "input_1m": 3.00,
        "output_1m": 15.00,
        "cached_input_1m": 0.30
      },
      "capabilities": {
        "context_window": 200000,
        "max_output_tokens": 8192,
        "latency_index": 0.92,
        "supports_vision": true,
        "supports_function_calling": true,
        "supports_json_mode": true,
        "supports_streaming": true
      },
      "tier": "flagship",
      "status": "active"
    },
    {
      "id": "claude-3-opus",
      "name": "Claude 3 Opus",
      "provider": "Anthropic",
      "provider_id": "anthropic",
      "description": "Most powerful Claude model for highly complex tasks",
      "release_date": "2024-03-04",
      "pricing": {
        "input_1m": 15.00,
        "output_1m": 75.00,
        "cached_input_1m": 1.50
      },
      "capabilities": {
        "context_window": 200000,
        "max_output_tokens": 4096,
        "latency_index": 0.70,
        "supports_vision": true,
        "supports_function_calling": true,
        "supports_json_mode": true,
        "supports_streaming": true
      },
      "tier": "flagship",
      "status": "active"
    },
    {
      "id": "claude-3.5-haiku",
      "name": "Claude 3.5 Haiku",
      "provider": "Anthropic",
      "provider_id": "anthropic",
      "description": "Fastest and most affordable Claude model",
      "release_date": "2024-10-22",
      "pricing": {
        "input_1m": 0.80,
        "output_1m": 4.00,
        "cached_input_1m": 0.08
      },
      "capabilities": {
        "context_window": 200000,
        "max_output_tokens": 8192,
        "latency_index": 0.98,
        "supports_vision": true,
        "supports_function_calling": true,
        "supports_json_mode": true,
        "supports_streaming": true
      },
      "tier": "economy",
      "status": "active"
    },
    {
      "id": "claude-opus-4",
      "name": "Claude Opus 4",
      "provider": "Anthropic",
      "provider_id": "anthropic",
      "description": "Latest generation flagship with extended thinking capabilities",
      "release_date": "2025-01-15",
      "pricing": {
        "input_1m": 15.00,
        "output_1m": 75.00,
        "cached_input_1m": 1.50
      },
      "capabilities": {
        "context_window": 200000,
        "max_output_tokens": 32000,
        "latency_index": 0.65,
        "supports_vision": true,
        "supports_function_calling": true,
        "supports_json_mode": true,
        "supports_streaming": true
      },
      "tier": "flagship",
      "status": "active"
    },
    {
      "id": "claude-sonnet-4",
      "name": "Claude Sonnet 4",
      "provider": "Anthropic",
      "provider_id": "anthropic",
      "description": "Next-generation balanced performance model",
      "release_date": "2025-01-15",
      "pricing": {
        "input_1m": 3.00,
        "output_1m": 15.00,
        "cached_input_1m": 0.30
      },
      "capabilities": {
        "context_window": 200000,
        "max_output_tokens": 16000,
        "latency_index": 0.90,
        "supports_vision": true,
        "supports_function_calling": true,
        "supports_json_mode": true,
        "supports_streaming": true
      },
      "tier": "flagship",
      "status": "active"
    },
    {
      "id": "gemini-1.5-pro",
      "name": "Gemini 1.5 Pro",
      "provider": "Google",
      "provider_id": "google",
      "description": "Best-in-class long context with up to 2M tokens",
      "release_date": "2024-02-15",
      "pricing": {
        "input_1m": 1.25,
        "output_1m": 5.00,
        "cached_input_1m": 0.3125
      },
      "capabilities": {
        "context_window": 2000000,
        "max_output_tokens": 8192,
        "latency_index": 0.88,
        "supports_vision": true,
        "supports_function_calling": true,
        "supports_json_mode": true,
        "supports_streaming": true
      },
      "tier": "flagship",
      "status": "active"
    },
    {
      "id": "gemini-1.5-flash",
      "name": "Gemini 1.5 Flash",
      "provider": "Google",
      "provider_id": "google",
      "description": "Fast and versatile multimodal model",
      "release_date": "2024-05-14",
      "pricing": {
        "input_1m": 0.075,
        "output_1m": 0.30,
        "cached_input_1m": 0.01875
      },
      "capabilities": {
        "context_window": 1000000,
        "max_output_tokens": 8192,
        "latency_index": 0.96,
        "supports_vision": true,
        "supports_function_calling": true,
        "supports_json_mode": true,
        "supports_streaming": true
      },
      "tier": "economy",
      "status": "active"
    },
    {
      "id": "gemini-2.0-flash",
      "name": "Gemini 2.0 Flash",
      "provider": "Google",
      "provider_id": "google",
      "description": "Next-generation multimodal with native tool use",
      "release_date": "2024-12-11",
      "pricing": {
        "input_1m": 0.10,
        "output_1m": 0.40,
        "cached_input_1m": 0.025
      },
      "capabilities": {
        "context_window": 1000000,
        "max_output_tokens": 8192,
        "latency_index": 0.97,
        "supports_vision": true,
        "supports_function_calling": true,
        "supports_json_mode": true,
        "supports_streaming": true
      },
      "tier": "economy",
      "status": "active"
    },
    {
      "id": "gemini-2.0-flash-thinking",
      "name": "Gemini 2.0 Flash Thinking",
      "provider": "Google",
      "provider_id": "google",
      "description": "Experimental reasoning model with visible thought process",
      "release_date": "2024-12-19",
      "pricing": {
        "input_1m": 0.10,
        "output_1m": 0.40,
        "cached_input_1m": 0.025
      },
      "capabilities": {
        "context_window": 1000000,
        "max_output_tokens": 8192,
        "latency_index": 0.85,
        "supports_vision": true,
        "supports_function_calling": false,
        "supports_json_mode": false,
        "supports_streaming": true
      },
      "tier": "reasoning",
      "status": "experimental"
    },
    {
      "id": "mistral-large",
      "name": "Mistral Large",
      "provider": "Mistral AI",
      "provider_id": "mistral",
      "description": "Top-tier reasoning model for complex tasks",
      "release_date": "2024-11-18",
      "pricing": {
        "input_1m": 2.00,
        "output_1m": 6.00,
        "cached_input_1m": 1.00
      },
      "capabilities": {
        "context_window": 128000,
        "max_output_tokens": 8192,
        "latency_index": 0.85,
        "supports_vision": true,
        "supports_function_calling": true,
        "supports_json_mode": true,
        "supports_streaming": true
      },
      "tier": "flagship",
      "status": "active"
    },
    {
      "id": "mistral-small",
      "name": "Mistral Small",
      "provider": "Mistral AI",
      "provider_id": "mistral",
      "description": "Cost-efficient model for bulk operations",
      "release_date": "2024-09-24",
      "pricing": {
        "input_1m": 0.20,
        "output_1m": 0.60,
        "cached_input_1m": 0.10
      },
      "capabilities": {
        "context_window": 32000,
        "max_output_tokens": 8192,
        "latency_index": 0.92,
        "supports_vision": false,
        "supports_function_calling": true,
        "supports_json_mode": true,
        "supports_streaming": true
      },
      "tier": "economy",
      "status": "active"
    },
    {
      "id": "codestral",
      "name": "Codestral",
      "provider": "Mistral AI",
      "provider_id": "mistral",
      "description": "Specialized model for code generation and analysis",
      "release_date": "2024-05-29",
      "pricing": {
        "input_1m": 0.20,
        "output_1m": 0.60,
        "cached_input_1m": 0.10
      },
      "capabilities": {
        "context_window": 32000,
        "max_output_tokens": 8192,
        "latency_index": 0.94,
        "supports_vision": false,
        "supports_function_calling": true,
        "supports_json_mode": true,
        "supports_streaming": true
      },
      "tier": "specialized",
      "status": "active"
    },
    {
      "id": "llama-3.3-70b",
      "name": "Llama 3.3 70B",
      "provider": "Meta",
      "provider_id": "meta",
      "description": "Open-weight model matching larger model performance",
      "release_date": "2024-12-06",
      "pricing": {
        "input_1m": 0.70,
        "output_1m": 0.80,
        "cached_input_1m": 0.35
      },
      "capabilities": {
        "context_window": 128000,
        "max_output_tokens": 8192,
        "latency_index": 0.88,
        "supports_vision": false,
        "supports_function_calling": true,
        "supports_json_mode": true,
        "supports_streaming": true
      },
      "tier": "flagship",
      "status": "active"
    },
    {
      "id": "llama-3.2-90b-vision",
      "name": "Llama 3.2 90B Vision",
      "provider": "Meta",
      "provider_id": "meta",
      "description": "Multimodal open-weight model with vision capabilities",
      "release_date": "2024-09-25",
      "pricing": {
        "input_1m": 0.90,
        "output_1m": 0.90,
        "cached_input_1m": 0.45
      },
      "capabilities": {
        "context_window": 128000,
        "max_output_tokens": 8192,
        "latency_index": 0.82,
        "supports_vision": true,
        "supports_function_calling": true,
        "supports_json_mode": true,
        "supports_streaming": true
      },
      "tier": "flagship",
      "status": "active"
    },
    {
      "id": "llama-3.2-11b-vision",
      "name": "Llama 3.2 11B Vision",
      "provider": "Meta",
      "provider_id": "meta",
      "description": "Efficient multimodal model for edge deployment",
      "release_date": "2024-09-25",
      "pricing": {
        "input_1m": 0.055,
        "output_1m": 0.055,
        "cached_input_1m": 0.0275
      },
      "capabilities": {
        "context_window": 128000,
        "max_output_tokens": 8192,
        "latency_index": 0.95,
        "supports_vision": true,
        "supports_function_calling": true,
        "supports_json_mode": true,
        "supports_streaming": true
      },
      "tier": "economy",
      "status": "active"
    },
    {
      "id": "command-r-plus",
      "name": "Command R+",
      "provider": "Cohere",
      "provider_id": "cohere",
      "description": "Enterprise-grade RAG and tool use model",
      "release_date": "2024-04-04",
      "pricing": {
        "input_1m": 2.50,
        "output_1m": 10.00,
        "cached_input_1m": 1.25
      },
      "capabilities": {
        "context_window": 128000,
        "max_output_tokens": 4096,
        "latency_index": 0.82,
        "supports_vision": false,
        "supports_function_calling": true,
        "supports_json_mode": true,
        "supports_streaming": true
      },
      "tier": "flagship",
      "status": "active"
    },
    {
      "id": "command-r",
      "name": "Command R",
      "provider": "Cohere",
      "provider_id": "cohere",
      "description": "Efficient model optimized for RAG workflows",
      "release_date": "2024-03-11",
      "pricing": {
        "input_1m": 0.15,
        "output_1m": 0.60,
        "cached_input_1m": 0.075
      },
      "capabilities": {
        "context_window": 128000,
        "max_output_tokens": 4096,
        "latency_index": 0.90,
        "supports_vision": false,
        "supports_function_calling": true,
        "supports_json_mode": true,
        "supports_streaming": true
      },
      "tier": "economy",
      "status": "active"
    },
    {
      "id": "deepseek-v3",
      "name": "DeepSeek V3",
      "provider": "DeepSeek",
      "provider_id": "deepseek",
      "description": "Cost-effective MoE model with strong reasoning",
      "release_date": "2024-12-26",
      "pricing": {
        "input_1m": 0.27,
        "output_1m": 1.10,
        "cached_input_1m": 0.07
      },
      "capabilities": {
        "context_window": 128000,
        "max_output_tokens": 8192,
        "latency_index": 0.88,
        "supports_vision": false,
        "supports_function_calling": true,
        "supports_json_mode": true,
        "supports_streaming": true
      },
      "tier": "flagship",
      "status": "active"
    },
    {
      "id": "deepseek-r1",
      "name": "DeepSeek R1",
      "provider": "DeepSeek",
      "provider_id": "deepseek",
      "description": "Reasoning model with transparent thought chains",
      "release_date": "2025-01-20",
      "pricing": {
        "input_1m": 0.55,
        "output_1m": 2.19,
        "cached_input_1m": 0.14
      },
      "capabilities": {
        "context_window": 128000,
        "max_output_tokens": 8192,
        "latency_index": 0.75,
        "supports_vision": false,
        "supports_function_calling": true,
        "supports_json_mode": true,
        "supports_streaming": true
      },
      "tier": "reasoning",
      "status": "active"
    }
  ]
}
