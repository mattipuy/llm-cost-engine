<div class="min-h-screen bg-gray-50">
  <article class="max-w-3xl mx-auto px-4 py-12 sm:py-16">
    <!-- Breadcrumb -->
    <nav class="text-sm text-gray-500 mb-8" aria-label="Breadcrumb">
      <ol class="flex items-center gap-1.5">
        <li><a routerLink="/tools/chatbot-simulator" class="hover:text-indigo-600 transition-colors">Home</a></li>
        <li class="before:content-['/'] before:mx-1.5">Blog</li>
        <li class="before:content-['/'] before:mx-1.5 text-gray-900 font-medium">How We Calculate LLM TCO</li>
      </ol>
    </nav>

    <!-- Header -->
    <header class="mb-10">
      <h1 class="text-3xl sm:text-4xl font-bold text-gray-900 leading-tight">
        We Open-Sourced the Math Behind LLM Cost Rankings
      </h1>
      <p class="mt-3 text-lg text-gray-600 italic">
        16 models. 7 providers. Weekly price tracking. Here's the formula.
      </p>
      <time datetime="2026-02-10" class="mt-4 block text-sm text-gray-400">February 10, 2026</time>
    </header>

    <hr class="border-gray-200 mb-10">

    <!-- Intro -->
    <div class="space-y-4 text-gray-700 leading-relaxed">
      <p>Every LLM provider shows you $/1M tokens.</p>
      <p>That number looks precise. It isn't.</p>
      <p class="font-semibold text-gray-900">
        $/1M tokens is not your monthly cost. It's a unit price detached from workload reality.
      </p>
      <p>
        The difference between those two can be thousands of dollars per year. GPT-4o at $2.50/1M input
        looks cheap until you run 10,000 messages a day with 500-token outputs at $10.00/1M &mdash;
        and suddenly you're at $2,250/month.
      </p>
      <p>Most teams only discover this after the invoice arrives.</p>
      <p>
        We built <a routerLink="/tools/chatbot-simulator" class="text-indigo-600 hover:text-indigo-800 underline">LLM Cost Engine</a>
        to calculate real monthly costs, deterministically. No opinions, no hidden weights, no vendor deals.
      </p>
      <p>This is the exact math we use.</p>
    </div>

    <hr class="border-gray-200 my-10">

    <!-- The Cost Formula -->
    <section class="mb-10">
      <h2 class="text-2xl font-semibold text-gray-900 mb-4">The Cost Formula</h2>
      <p class="text-gray-700 mb-4">Four inputs, three price dimensions, one deterministic output.</p>

      <pre class="bg-gray-900 text-green-400 rounded-lg p-5 overflow-x-auto text-sm leading-relaxed"><code>M  = Messages per day
Ti = Input tokens per message
To = Output tokens per message
Cr = Cache hit rate (0.00 - 1.00)

Daily cost:
  C_input_fresh  = (M &times; Ti &times; (1 - Cr)) / 1,000,000 &times; P_input
  C_input_cached = (M &times; Ti &times; Cr)       / 1,000,000 &times; P_cached
  C_output       = (M &times; To)            / 1,000,000 &times; P_output

Monthly cost = (C_input_fresh + C_input_cached + C_output) &times; 30</code></pre>

      <p class="mt-4 text-gray-700">
        That's it. This is the exact formula in our codebase. Every number in the calculator traces back to this math.
      </p>
    </section>

    <!-- Why Input/Output Separation Matters -->
    <section class="mb-10">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Why Input/Output Separation Matters</h3>
      <p class="text-gray-700 mb-4">Most calculators treat all tokens equally. They shouldn't.</p>

      <div class="overflow-x-auto">
        <table class="w-full text-sm border border-gray-200 rounded-lg overflow-hidden">
          <thead class="bg-gray-100">
            <tr>
              <th class="text-left px-4 py-2.5 font-semibold text-gray-900">Model</th>
              <th class="text-right px-4 py-2.5 font-semibold text-gray-900 tabular-nums">Input $/1M</th>
              <th class="text-right px-4 py-2.5 font-semibold text-gray-900 tabular-nums">Output $/1M</th>
              <th class="text-right px-4 py-2.5 font-semibold text-gray-900">Ratio</th>
            </tr>
          </thead>
          <tbody class="divide-y divide-gray-200">
            <tr>
              <td class="px-4 py-2.5 text-gray-700">GPT-4o</td>
              <td class="px-4 py-2.5 text-right tabular-nums text-gray-700">$2.50</td>
              <td class="px-4 py-2.5 text-right tabular-nums text-gray-700">$10.00</td>
              <td class="px-4 py-2.5 text-right font-semibold text-gray-900">4x</td>
            </tr>
            <tr>
              <td class="px-4 py-2.5 text-gray-700">Claude Opus 4</td>
              <td class="px-4 py-2.5 text-right tabular-nums text-gray-700">$15.00</td>
              <td class="px-4 py-2.5 text-right tabular-nums text-gray-700">$75.00</td>
              <td class="px-4 py-2.5 text-right font-semibold text-gray-900">5x</td>
            </tr>
            <tr>
              <td class="px-4 py-2.5 text-gray-700">Gemini 2.0 Flash</td>
              <td class="px-4 py-2.5 text-right tabular-nums text-gray-700">$0.10</td>
              <td class="px-4 py-2.5 text-right tabular-nums text-gray-700">$0.40</td>
              <td class="px-4 py-2.5 text-right font-semibold text-gray-900">4x</td>
            </tr>
          </tbody>
        </table>
      </div>

      <p class="mt-4 text-gray-700">
        Output tokens cost 4&ndash;5x more than input across every major model. A chatbot generating long
        responses has a fundamentally different cost profile than a pipeline extracting short JSON.
        We separate them because real workloads aren't symmetric.
      </p>
    </section>

    <!-- The Cache Variable -->
    <section class="mb-10">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">The Cache Variable</h3>
      <p class="text-gray-700 mb-4">Prompt caching discounts are the most overlooked cost lever in LLM pricing:</p>

      <div class="overflow-x-auto">
        <table class="w-full text-sm border border-gray-200 rounded-lg overflow-hidden">
          <thead class="bg-gray-100">
            <tr>
              <th class="text-left px-4 py-2.5 font-semibold text-gray-900">Model</th>
              <th class="text-right px-4 py-2.5 font-semibold text-gray-900 tabular-nums">Standard Input</th>
              <th class="text-right px-4 py-2.5 font-semibold text-gray-900 tabular-nums">Cached Input</th>
              <th class="text-right px-4 py-2.5 font-semibold text-gray-900">Discount</th>
            </tr>
          </thead>
          <tbody class="divide-y divide-gray-200">
            <tr>
              <td class="px-4 py-2.5 text-gray-700">Claude 3.5 Sonnet</td>
              <td class="px-4 py-2.5 text-right tabular-nums text-gray-700">$3.00</td>
              <td class="px-4 py-2.5 text-right tabular-nums text-gray-700">$0.30</td>
              <td class="px-4 py-2.5 text-right font-semibold text-green-700">90%</td>
            </tr>
            <tr>
              <td class="px-4 py-2.5 text-gray-700">Gemini 2.0 Flash</td>
              <td class="px-4 py-2.5 text-right tabular-nums text-gray-700">$0.10</td>
              <td class="px-4 py-2.5 text-right tabular-nums text-gray-700">$0.025</td>
              <td class="px-4 py-2.5 text-right font-semibold text-green-700">75%</td>
            </tr>
            <tr>
              <td class="px-4 py-2.5 text-gray-700">DeepSeek V3</td>
              <td class="px-4 py-2.5 text-right tabular-nums text-gray-700">$0.27</td>
              <td class="px-4 py-2.5 text-right tabular-nums text-gray-700">$0.07</td>
              <td class="px-4 py-2.5 text-right font-semibold text-green-700">74%</td>
            </tr>
            <tr>
              <td class="px-4 py-2.5 text-gray-700">GPT-4o</td>
              <td class="px-4 py-2.5 text-right tabular-nums text-gray-700">$2.50</td>
              <td class="px-4 py-2.5 text-right tabular-nums text-gray-700">$1.25</td>
              <td class="px-4 py-2.5 text-right font-semibold text-green-700">50%</td>
            </tr>
          </tbody>
        </table>
      </div>

      <p class="mt-4 text-gray-700">
        A support bot with a static system prompt hitting 80% cache rate pays dramatically less than
        one with dynamic prompts. If a model doesn't publish a cached price, we fall back to the
        standard input price. No assumptions.
      </p>
    </section>

    <hr class="border-gray-200 my-10">

    <!-- ValueScore -->
    <section class="mb-10">
      <h2 class="text-2xl font-semibold text-gray-900 mb-4">ValueScore: Deterministic Ranking</h2>
      <p class="text-gray-700 mb-4">
        Cost alone doesn't determine the best model. A model at $0.01/month with an 8K context window
        and 3-second latency isn't "best value."
      </p>

      <pre class="bg-gray-900 text-green-400 rounded-lg p-5 overflow-x-auto text-sm leading-relaxed"><code>ValueScore = (1 / Cost)^0.65 &times; log10(Context)^0.35 &times; LatencyIndex</code></pre>

      <p class="mt-4 text-gray-700 mb-4">Three factors. Fixed weights. No manual overrides.</p>

      <div class="overflow-x-auto">
        <table class="w-full text-sm border border-gray-200 rounded-lg overflow-hidden">
          <thead class="bg-gray-100">
            <tr>
              <th class="text-left px-4 py-2.5 font-semibold text-gray-900">Factor</th>
              <th class="text-right px-4 py-2.5 font-semibold text-gray-900">Weight</th>
              <th class="text-left px-4 py-2.5 font-semibold text-gray-900">Rationale</th>
            </tr>
          </thead>
          <tbody class="divide-y divide-gray-200">
            <tr>
              <td class="px-4 py-2.5 font-mono text-sm text-gray-700">(1 / Cost)^0.65</td>
              <td class="px-4 py-2.5 text-right tabular-nums text-gray-700">65%</td>
              <td class="px-4 py-2.5 text-gray-700">This is a cost calculator. Cost dominates.</td>
            </tr>
            <tr>
              <td class="px-4 py-2.5 font-mono text-sm text-gray-700">log10(Context)^0.35</td>
              <td class="px-4 py-2.5 text-right tabular-nums text-gray-700">35%</td>
              <td class="px-4 py-2.5 text-gray-700">Context matters, but 1M vs 2M is marginal. Log scale captures diminishing returns.</td>
            </tr>
            <tr>
              <td class="px-4 py-2.5 font-mono text-sm text-gray-700">LatencyIndex</td>
              <td class="px-4 py-2.5 text-right tabular-nums text-gray-700">0&ndash;1</td>
              <td class="px-4 py-2.5 text-gray-700">Sourced from benchmarks. Fast models score higher.</td>
            </tr>
          </tbody>
        </table>
      </div>

      <p class="mt-4 text-gray-700">
        The weights are named constants in a source file you can read:
        <code class="bg-gray-100 px-1.5 py-0.5 rounded text-sm font-mono">VALUESCORE_ALPHA = 0.65</code>,
        <code class="bg-gray-100 px-1.5 py-0.5 rounded text-sm font-mono">VALUESCORE_BETA = 0.35</code>.
        Not buried in logic. Intentionally transparent.
      </p>

      <div class="mt-6 bg-amber-50 border border-amber-200 rounded-lg p-4">
        <p class="font-semibold text-amber-900 mb-2">What ValueScore does NOT do:</p>
        <ul class="list-disc list-inside text-amber-800 space-y-1 text-sm">
          <li>Measure output quality, reasoning, or coding ability</li>
          <li>Use subjective assessments or crowdsourced ratings</li>
          <li>Change based on who sponsors us (nobody does)</li>
        </ul>
      </div>

      <p class="mt-4 text-gray-700 font-medium">
        If two people enter the same inputs, they get the same ranking. Always.
      </p>
    </section>

    <hr class="border-gray-200 my-10">

    <!-- Deterministic > Opinion -->
    <section class="mb-10">
      <h2 class="text-2xl font-semibold text-gray-900 mb-4">Deterministic &gt; Opinion</h2>
      <p class="text-gray-700 mb-2">This is our design principle.</p>
      <p class="text-gray-700 mb-4">
        Benchmarking tools that hide their methodology ask you to trust them. We'd rather show you the math.
      </p>
      <ul class="list-disc list-inside text-gray-700 space-y-2">
        <li>
          The pricing dataset is public JSON:
          <a href="https://llm-cost-engine.vercel.app/data/llm-pricing.json"
             class="text-indigo-600 hover:text-indigo-800 underline font-mono text-sm"
             target="_blank" rel="noopener">llm-pricing.json</a>
        </li>
        <li>The ValueScore formula is four lines of TypeScript</li>
        <li>The weights are named constants, not magic numbers</li>
        <li>If you disagree with <code class="bg-gray-100 px-1.5 py-0.5 rounded text-sm font-mono">ALPHA = 0.65</code>, fork the logic and set your own</li>
      </ul>
      <p class="mt-4 text-gray-700 italic">
        A tool that produces different rankings depending on who is paying it isn't a tool &mdash; it's an ad.
      </p>
    </section>

    <hr class="border-gray-200 my-10">

    <!-- Routing -->
    <section class="mb-10">
      <h2 class="text-2xl font-semibold text-gray-900 mb-4">Routing: The 80/20 Strategy</h2>
      <p class="text-gray-700 mb-4">
        Not every query needs your most expensive model. Route 80% to GPT-4o Mini, 20% to Claude Sonnet:
      </p>

      <pre class="bg-gray-900 text-green-400 rounded-lg p-5 overflow-x-auto text-sm leading-relaxed"><code>($4.50 &times; 0.80) + ($13.50 &times; 0.20) = $6.30/mo  vs  $13.50/mo = 53% savings</code></pre>

      <p class="mt-4 text-gray-700">
        Our <a routerLink="/tools/chatbot-simulator" class="text-indigo-600 hover:text-indigo-800 underline">simulator</a>
        calculates this for any pair of models in the registry, in real-time.
      </p>
    </section>

    <hr class="border-gray-200 my-10">

    <!-- Price Tracking -->
    <section class="mb-10">
      <h2 class="text-2xl font-semibold text-gray-900 mb-4">Price Tracking: Weekly, Automated, Public</h2>
      <p class="text-gray-700 mb-4">
        We snapshot all 16 models' pricing every Sunday via automated cron. Every change is recorded
        &mdash; even increases.
      </p>
      <p class="text-gray-700 mb-4">
        When a price drops &ge; 5%, subscribers get an automatic digest email. No account needed,
        just an email address with double opt-in.
      </p>
      <p class="text-gray-700">
        The pricing dataset, detection logic, and alert threshold are public. Nothing is hidden behind an API.
      </p>
    </section>

    <hr class="border-gray-200 my-10">

    <!-- What We Don't Do -->
    <section class="mb-10">
      <h2 class="text-2xl font-semibold text-gray-900 mb-4">What We Don't Do</h2>
      <ol class="list-decimal list-inside text-gray-700 space-y-3">
        <li>
          <strong>No live latency benchmarking.</strong> Our latency index comes from provider docs and
          third-party data, not our own measurements.
          <a href="https://artificialanalysis.ai" class="text-indigo-600 hover:text-indigo-800 underline"
             target="_blank" rel="noopener">Artificial Analysis</a> does this better.
        </li>
        <li>
          <strong>No output quality evaluation.</strong> ValueScore is a cost metric, not a capability
          benchmark. Always test with your actual prompts.
        </li>
        <li>
          <strong>No vendor partnerships.</strong> We don't receive compensation from any LLM provider.
          All pricing is sourced from official pages and verified weekly.
        </li>
        <li>
          <strong>No rate limit modeling.</strong> The cheapest model might throttle at 1,000 RPM. We don't capture this.
        </li>
      </ol>
      <p class="mt-4 text-gray-700 italic">Transparency requires admitting what you don't measure.</p>
    </section>

    <hr class="border-gray-200 my-10">

    <!-- CTA -->
    <section class="mb-10">
      <h2 class="text-2xl font-semibold text-gray-900 mb-4">Try It</h2>
      <p class="text-gray-700 mb-4">
        If you're making model decisions based on pricing tables alone, you're likely underestimating real deployment cost.
      </p>
      <p class="text-gray-700 mb-6">
        Enter your workload. Compare up to 5 models. Enable routing. Run sensitivity at 2x and 3x.
      </p>
      <a
        routerLink="/tools/chatbot-simulator"
        class="inline-block px-6 py-3 bg-indigo-600 text-white font-medium rounded-lg hover:bg-indigo-700 transition-colors"
      >
        Open the Calculator
      </a>
      <p class="mt-6 text-sm text-gray-500">
        If you disagree with the weights, fork the math.
      </p>
    </section>

    <!-- Footer -->
    <footer class="border-t border-gray-200 pt-6 mt-10">
      <p class="text-sm text-gray-400">
        Pricing data: v1.3.0, 16 models, 7 providers. Sourced from official pricing pages, verified 2026-02-08. Updated weekly.
      </p>
    </footer>
  </article>
</div>
